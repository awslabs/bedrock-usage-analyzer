models:
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-DF0E34D4
          name: On-demand model inference requests per minute for Amazon Titan Multimodal
            Embeddings G1
        tpd: null
        tpm:
          code: L-ABC24664
          name: On-demand model inference tokens per minute for Amazon Titan Multimodal
            Embeddings G1
  inference_types:
  - ON_DEMAND
  model_id: amazon.titan-embed-image-v1
  provider: Amazon
- inference_types:
  - PROVISIONED
  model_id: amazon.titan-embed-image-v1:0
  provider: Amazon
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-26C560CE
          name: On-demand model inference requests per minute for Amazon Titan Text
            Embeddings V2
        tpd: null
        tpm:
          code: L-DE641971
          name: On-demand model inference tokens per minute for Amazon Titan Text
            Embeddings V2
  inference_types:
  - ON_DEMAND
  model_id: amazon.titan-embed-text-v2:0
  provider: Amazon
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-9EAB0D12
          name: On-demand model inference requests per minute for Amazon Titan Text
            Express
        tpd: null
        tpm:
          code: L-44992E63
          name: On-demand model inference tokens per minute for Amazon Titan Text
            Express
  inference_types:
  - ON_DEMAND
  model_id: amazon.titan-text-express-v1
  provider: Amazon
- inference_types:
  - PROVISIONED
  model_id: amazon.titan-text-express-v1:0:8k
  provider: Amazon
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-A70F1DE3
          name: On-demand model inference requests per minute for Amazon Titan Text
            Lite
        tpd: null
        tpm:
          code: L-70BE83E9
          name: On-demand model inference tokens per minute for Amazon Titan Text
            Lite
  inference_types:
  - ON_DEMAND
  model_id: amazon.titan-text-lite-v1
  provider: Amazon
- inference_types:
  - PROVISIONED
  model_id: amazon.titan-text-lite-v1:0:4k
  provider: Amazon
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-2DC80978
          name: On-demand model inference requests per minute for Anthropic Claude
            3 Haiku
        tpd: null
        tpm:
          code: L-8CE99163
          name: On-demand model inference tokens per minute for Anthropic Claude 3
            Haiku
  inference_types:
  - ON_DEMAND
  model_id: anthropic.claude-3-haiku-20240307-v1:0
  provider: Anthropic
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-F406804E
          name: On-demand model inference requests per minute for Anthropic Claude
            3 Sonnet
        tpd: null
        tpm:
          code: L-4C35BB2A
          name: On-demand model inference tokens per minute for Anthropic Claude 3
            Sonnet
  inference_types:
  - ON_DEMAND
  model_id: anthropic.claude-3-sonnet-20240229-v1:0
  provider: Anthropic
- endpoints:
    global:
      quotas:
        concurrent: null
        rpm:
          code: L-E5084BBA
          name: Global cross-region model inference requests per minute for Anthropic
            Claude Haiku 4.5
        tpd:
          code: L-B5C049AE
          name: Global cross-region model inference tokens per day for Anthropic Claude
            Haiku 4.5
        tpm:
          code: L-9A11C666
          name: Global cross-region model inference tokens per minute for Anthropic
            Claude Haiku 4.5
  inference_profiles:
  - global
  inference_types:
  - INFERENCE_PROFILE
  model_id: anthropic.claude-haiku-4-5-20251001-v1:0
  provider: Anthropic
- endpoints:
    global:
      quotas:
        concurrent: null
        rpm:
          code: L-DB84CE56
          name: Global cross-region model inference requests per minute for Anthropic
            Claude Sonnet 4.5 V1
        tpd:
          code: L-BC182137
          name: Global cross-region model inference tokens per day for Anthropic Claude
            Sonnet 4.5 V1
        tpm:
          code: L-27C57EE8
          name: Global cross-region model inference tokens per minute for Anthropic
            Claude Sonnet 4.5 V1
  inference_profiles:
  - global
  inference_types:
  - INFERENCE_PROFILE
  model_id: anthropic.claude-sonnet-4-5-20250929-v1:0
  provider: Anthropic
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-FF8E7864
          name: On-demand model inference requests per minute for Cohere Embed English
        tpd: null
        tpm:
          code: L-A2BE277A
          name: On-demand model inference tokens per minute for Cohere Embed English
  inference_types:
  - ON_DEMAND
  model_id: cohere.embed-english-v3
  provider: Cohere
- inference_types:
  - PROVISIONED
  model_id: cohere.embed-english-v3:0:512
  provider: Cohere
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm: null
        tpd: null
        tpm: null
  inference_types:
  - ON_DEMAND
  model_id: cohere.embed-multilingual-v3
  provider: Cohere
- inference_types:
  - PROVISIONED
  model_id: cohere.embed-multilingual-v3:0:512
  provider: Cohere
- endpoints:
    global:
      quotas:
        concurrent: null
        rpm:
          code: L-7089DC7D
          name: Global cross-region model inference requests per minute for Cohere
            Embed V4
        tpd:
          code: L-795ADAB0
          name: Global cross-region model inference tokens per day for Cohere Embed
            V4
        tpm:
          code: L-02DFBB76
          name: Global cross-region model inference tokens per minute for Cohere Embed
            V4
  inference_profiles:
  - global
  inference_types:
  - INFERENCE_PROFILE
  model_id: cohere.embed-v4:0
  provider: Cohere
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-D9A35062
          name: On-demand model inference requests per minute for Mistral 7B Instruct
        tpd: null
        tpm:
          code: L-02D831F1
          name: On-demand model inference tokens per minute for Mistral AI Mistral
            7B Instruct
  inference_types:
  - ON_DEMAND
  model_id: mistral.mistral-7b-instruct-v0:2
  provider: Mistral AI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-3AF844DB
          name: On-demand model inference requests per minute for Mistral Large
        tpd: null
        tpm:
          code: L-01447289
          name: On-demand model inference tokens per minute for Mistral AI Mistral
            Large
  inference_types:
  - ON_DEMAND
  model_id: mistral.mistral-large-2402-v1:0
  provider: Mistral AI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-FD938632
          name: On-demand model inference requests per minute for Mistral Mixtral
            8x7b Instruct
        tpd: null
        tpm:
          code: L-490F4D1F
          name: On-demand model inference tokens per minute for Mistral AI Mixtral
            8X7BB Instruct
  inference_types:
  - ON_DEMAND
  model_id: mistral.mixtral-8x7b-instruct-v0:1
  provider: Mistral AI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-25B50707
          name: On-demand model inference requests per minute for OpenAI GPT OSS 120B
        tpd: null
        tpm:
          code: L-9DC5F595
          name: On-demand model inference tokens per minute for OpenAI GPT OSS 120B
  inference_types:
  - ON_DEMAND
  model_id: openai.gpt-oss-120b-1:0
  provider: OpenAI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-AF7F0545
          name: On-demand model inference requests per minute for OpenAI GPT OSS 20B
        tpd: null
        tpm:
          code: L-036E14D8
          name: On-demand model inference tokens per minute for OpenAI GPT OSS 20B
  inference_types:
  - ON_DEMAND
  model_id: openai.gpt-oss-20b-1:0
  provider: OpenAI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-E880C759
          name: On-demand model inference requests per minute for Qwen3 32B V1
        tpd: null
        tpm:
          code: L-B7C52139
          name: On-demand model inference tokens per minute for Qwen3 32B V1
  inference_types:
  - ON_DEMAND
  model_id: qwen.qwen3-32b-v1:0
  provider: Qwen
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-66EE6E0B
          name: On-demand model inference requests per minute for Qwen3 Coder 30B
            a3b V1
        tpd: null
        tpm:
          code: L-92F81E14
          name: On-demand model inference tokens per minute for Qwen3 Coder 30B a3b
            V1
  inference_types:
  - ON_DEMAND
  model_id: qwen.qwen3-coder-30b-a3b-v1:0
  provider: Qwen
