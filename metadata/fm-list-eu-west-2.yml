models:
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-E386A278
          name: On-demand model inference requests per minute for Amazon Nova Lite
        tpd: null
        tpm:
          code: L-70423BF8
          name: On-demand model inference tokens per minute for Amazon Nova Lite
  inference_types:
  - ON_DEMAND
  model_id: amazon.nova-lite-v1:0
  provider: Amazon
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-E118F160
          name: On-demand model inference requests per minute for Amazon Nova Micro
        tpd: null
        tpm:
          code: L-CFA4FA0D
          name: On-demand model inference tokens per minute for Amazon Nova Micro
  inference_types:
  - ON_DEMAND
  model_id: amazon.nova-micro-v1:0
  provider: Amazon
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-F2717A44
          name: On-demand model inference requests per minute for Amazon Nova Pro
        tpd: null
        tpm:
          code: L-CE33604C
          name: On-demand model inference tokens per minute for Amazon Nova Pro
  inference_types:
  - ON_DEMAND
  model_id: amazon.nova-pro-v1:0
  provider: Amazon
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-DF0E34D4
          name: On-demand model inference requests per minute for Amazon Titan Multimodal
            Embeddings G1
        tpd: null
        tpm:
          code: L-ABC24664
          name: On-demand model inference tokens per minute for Amazon Titan Multimodal
            Embeddings G1
  inference_types:
  - ON_DEMAND
  model_id: amazon.titan-embed-image-v1
  provider: Amazon
- inference_types:
  - PROVISIONED
  model_id: amazon.titan-embed-image-v1:0
  provider: Amazon
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-26C560CE
          name: On-demand model inference requests per minute for Amazon Titan Text
            Embeddings V2
        tpd: null
        tpm:
          code: L-DE641971
          name: On-demand model inference tokens per minute for Amazon Titan Text
            Embeddings V2
  inference_types:
  - ON_DEMAND
  model_id: amazon.titan-embed-text-v2:0
  provider: Amazon
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-7DBB06FD
          name: On-demand model inference requests per minute for Amazon Titan Image
            Generator G1
        tpd: null
        tpm:
          code: L-2B715ABD
          name: On-demand model inference tokens per minute for Amazon Titan Image
            Generator G1
  inference_types:
  - ON_DEMAND
  model_id: amazon.titan-image-generator-v1
  provider: Amazon
- inference_types:
  - PROVISIONED
  model_id: amazon.titan-image-generator-v1:0
  provider: Amazon
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-9EAB0D12
          name: On-demand model inference requests per minute for Amazon Titan Text
            Express
        tpd: null
        tpm:
          code: L-44992E63
          name: On-demand model inference tokens per minute for Amazon Titan Text
            Express
  inference_types:
  - ON_DEMAND
  model_id: amazon.titan-text-express-v1
  provider: Amazon
- inference_types:
  - PROVISIONED
  model_id: amazon.titan-text-express-v1:0:8k
  provider: Amazon
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-A70F1DE3
          name: On-demand model inference requests per minute for Amazon Titan Text
            Lite
        tpd: null
        tpm:
          code: L-70BE83E9
          name: On-demand model inference tokens per minute for Amazon Titan Text
            Lite
  inference_types:
  - ON_DEMAND
  model_id: amazon.titan-text-lite-v1
  provider: Amazon
- inference_types:
  - PROVISIONED
  model_id: amazon.titan-text-lite-v1:0:4k
  provider: Amazon
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-0651A8FB
          name: On-demand model inference requests per minute for Anthropic Claude
            3.7 Sonnet V1
        tpd: null
        tpm:
          code: L-8F2EEEA3
          name: On-demand model inference tokens per minute for Anthropic Claude 3.7
            Sonnet V1
  inference_types:
  - ON_DEMAND
  model_id: anthropic.claude-3-7-sonnet-20250219-v1:0
  provider: Anthropic
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-2DC80978
          name: On-demand model inference requests per minute for Anthropic Claude
            3 Haiku
        tpd: null
        tpm:
          code: L-8CE99163
          name: On-demand model inference tokens per minute for Anthropic Claude 3
            Haiku
  inference_types:
  - ON_DEMAND
  model_id: anthropic.claude-3-haiku-20240307-v1:0
  provider: Anthropic
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-F406804E
          name: On-demand model inference requests per minute for Anthropic Claude
            3 Sonnet
        tpd: null
        tpm:
          code: L-4C35BB2A
          name: On-demand model inference tokens per minute for Anthropic Claude 3
            Sonnet
  inference_types:
  - ON_DEMAND
  model_id: anthropic.claude-3-sonnet-20240229-v1:0
  provider: Anthropic
- endpoints:
    eu:
      quotas:
        concurrent: null
        rpm:
          code: L-CCA5DF70
          name: Cross-region model inference requests per minute for Anthropic Claude
            Haiku 4.5
        tpd:
          code: L-B5C049AE
          name: Global cross-region model inference tokens per day for Anthropic Claude
            Haiku 4.5
        tpm:
          code: L-58BE175A
          name: Cross-region model inference tokens per minute for Anthropic Claude
            Haiku 4.5
    global:
      quotas:
        concurrent: null
        rpm:
          code: L-E5084BBA
          name: Global cross-region model inference requests per minute for Anthropic
            Claude Haiku 4.5
        tpd:
          code: L-B5C049AE
          name: Global cross-region model inference tokens per day for Anthropic Claude
            Haiku 4.5
        tpm:
          code: L-9A11C666
          name: Global cross-region model inference tokens per minute for Anthropic
            Claude Haiku 4.5
  inference_profiles:
  - eu
  - global
  inference_types:
  - INFERENCE_PROFILE
  model_id: anthropic.claude-haiku-4-5-20251001-v1:0
  provider: Anthropic
- endpoints:
    eu:
      quotas:
        concurrent: null
        rpm:
          code: L-4A6BFAB1
          name: Cross-region model inference requests per minute for Anthropic Claude
            Sonnet 4.5 V1
        tpd:
          code: L-381AD9EE
          name: Model invocation max tokens per day for Anthropic Claude Sonnet 4.5
            V1 (doubled for cross-region calls)
        tpm:
          code: L-F4DDD3EB
          name: Cross-region model inference tokens per minute for Anthropic Claude
            Sonnet 4.5 V1
    global:
      quotas:
        concurrent: null
        rpm:
          code: L-DB84CE56
          name: Global cross-region model inference requests per minute for Anthropic
            Claude Sonnet 4.5 V1
        tpd:
          code: L-BC182137
          name: Global cross-region model inference tokens per day for Anthropic Claude
            Sonnet 4.5 V1
        tpm:
          code: L-27C57EE8
          name: Global cross-region model inference tokens per minute for Anthropic
            Claude Sonnet 4.5 V1
  inference_profiles:
  - eu
  - global
  inference_types:
  - INFERENCE_PROFILE
  model_id: anthropic.claude-sonnet-4-5-20250929-v1:0
  provider: Anthropic
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-FF8E7864
          name: On-demand model inference requests per minute for Cohere Embed English
        tpd: null
        tpm:
          code: L-A2BE277A
          name: On-demand model inference tokens per minute for Cohere Embed English
  inference_types:
  - ON_DEMAND
  model_id: cohere.embed-english-v3
  provider: Cohere
- inference_types:
  - PROVISIONED
  model_id: cohere.embed-english-v3:0:512
  provider: Cohere
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm: null
        tpd: null
        tpm: null
  inference_types:
  - ON_DEMAND
  model_id: cohere.embed-multilingual-v3
  provider: Cohere
- inference_types:
  - PROVISIONED
  model_id: cohere.embed-multilingual-v3:0:512
  provider: Cohere
- endpoints:
    global:
      quotas:
        concurrent: null
        rpm:
          code: L-7089DC7D
          name: Global cross-region model inference requests per minute for Cohere
            Embed V4
        tpd:
          code: L-795ADAB0
          name: Global cross-region model inference tokens per day for Cohere Embed
            V4
        tpm:
          code: L-02DFBB76
          name: Global cross-region model inference tokens per minute for Cohere Embed
            V4
  inference_profiles:
  - global
  inference_types:
  - INFERENCE_PROFILE
  model_id: cohere.embed-v4:0
  provider: Cohere
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-7A5451CB
          name: On-demand model inference requests per minute for DeepSeek V3 V1
        tpd: null
        tpm:
          code: L-30A6895A
          name: On-demand model inference tokens per minute for DeepSeek V3 V1
  inference_types:
  - ON_DEMAND
  model_id: deepseek.v3-v1:0
  provider: DeepSeek
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-46D383AF
          name: On-demand model inference requests per minute for Meta Llama 3 70B
            Instruct
        tpd: null
        tpm:
          code: L-609E24B0
          name: On-demand model inference tokens per minute for Meta Llama 3 70B Instruct
  inference_types:
  - ON_DEMAND
  model_id: meta.llama3-70b-instruct-v1:0
  provider: Meta
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-320BEFEB
          name: On-demand model inference requests per minute for Meta Llama 3 8B
            Instruct
        tpd: null
        tpm:
          code: L-03A9B835
          name: On-demand model inference tokens per minute for Meta Llama 3 8B Instruct
  inference_types:
  - ON_DEMAND
  model_id: meta.llama3-8b-instruct-v1:0
  provider: Meta
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-D9A35062
          name: On-demand model inference requests per minute for Mistral 7B Instruct
        tpd: null
        tpm:
          code: L-02D831F1
          name: On-demand model inference tokens per minute for Mistral AI Mistral
            7B Instruct
  inference_types:
  - ON_DEMAND
  model_id: mistral.mistral-7b-instruct-v0:2
  provider: Mistral AI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-3AF844DB
          name: On-demand model inference requests per minute for Mistral Large
        tpd: null
        tpm:
          code: L-01447289
          name: On-demand model inference tokens per minute for Mistral AI Mistral
            Large
  inference_types:
  - ON_DEMAND
  model_id: mistral.mistral-large-2402-v1:0
  provider: Mistral AI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-FD938632
          name: On-demand model inference requests per minute for Mistral Mixtral
            8x7b Instruct
        tpd: null
        tpm:
          code: L-490F4D1F
          name: On-demand model inference tokens per minute for Mistral AI Mixtral
            8X7BB Instruct
  inference_types:
  - ON_DEMAND
  model_id: mistral.mixtral-8x7b-instruct-v0:1
  provider: Mistral AI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-25B50707
          name: On-demand model inference requests per minute for OpenAI GPT OSS 120B
        tpd: null
        tpm:
          code: L-9DC5F595
          name: On-demand model inference tokens per minute for OpenAI GPT OSS 120B
  inference_types:
  - ON_DEMAND
  model_id: openai.gpt-oss-120b-1:0
  provider: OpenAI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-AF7F0545
          name: On-demand model inference requests per minute for OpenAI GPT OSS 20B
        tpd: null
        tpm:
          code: L-036E14D8
          name: On-demand model inference tokens per minute for OpenAI GPT OSS 20B
  inference_types:
  - ON_DEMAND
  model_id: openai.gpt-oss-20b-1:0
  provider: OpenAI
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-548A1A32
          name: On-demand model inference requests per minute for Qwen3 235B a22b
            2507 V1
        tpd: null
        tpm:
          code: L-3875BCCF
          name: On-demand model inference tokens per minute for Qwen3 235B a22b 2507
            V1
  inference_types:
  - ON_DEMAND
  model_id: qwen.qwen3-235b-a22b-2507-v1:0
  provider: Qwen
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-E880C759
          name: On-demand model inference requests per minute for Qwen3 32B V1
        tpd: null
        tpm:
          code: L-B7C52139
          name: On-demand model inference tokens per minute for Qwen3 32B V1
  inference_types:
  - ON_DEMAND
  model_id: qwen.qwen3-32b-v1:0
  provider: Qwen
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-66EE6E0B
          name: On-demand model inference requests per minute for Qwen3 Coder 30B
            a3b V1
        tpd: null
        tpm:
          code: L-92F81E14
          name: On-demand model inference tokens per minute for Qwen3 Coder 30B a3b
            V1
  inference_types:
  - ON_DEMAND
  model_id: qwen.qwen3-coder-30b-a3b-v1:0
  provider: Qwen
- endpoints:
    base:
      quotas:
        concurrent: null
        rpm:
          code: L-CBE7E3CD
          name: On-demand model inference requests per minute for Qwen3 Coder 480B
            a35b V1
        tpd: null
        tpm:
          code: L-4D0E44C8
          name: On-demand model inference tokens per minute for Qwen3 Coder 480B a35b
            V1
  inference_types:
  - ON_DEMAND
  model_id: qwen.qwen3-coder-480b-a35b-v1:0
  provider: Qwen
